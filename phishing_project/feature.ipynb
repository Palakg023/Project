{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f229f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "import re\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import socket\n",
    "import requests\n",
    "from googlesearch import search\n",
    "import whois\n",
    "from datetime import date, datetime\n",
    "import time\n",
    "from dateutil.parser import parse as date_parse\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "class FeatureExtraction:\n",
    "    features = []\n",
    "    def __init__(self,url):\n",
    "        self.features = []\n",
    "        self.url = url\n",
    "        self.domain = \"\"\n",
    "        self.whois_response = \"\"\n",
    "        self.urlparse = \"\"\n",
    "        self.response = \"\"\n",
    "        self.soup = \"\"\n",
    "\n",
    "        try:\n",
    "            self.response = requests.get(url)\n",
    "            self.soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            self.urlparse = urlparse(url)\n",
    "            self.domain = self.urlparse.netloc\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            self.whois_response = whois.whois(self.domain)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        self.features.append(self.UsingIp())\n",
    "        self.features.append(self.shortUrl())\n",
    "        self.features.append(self.prefixSuffix())\n",
    "        self.features.append(self.SubDomains())\n",
    "        self.features.append(self.Hppts())\n",
    "        self.features.append(self.Favicon())\n",
    "        \n",
    "\n",
    "        self.features.append(self.NonStdPort())\n",
    "        self.features.append(self.HTTPSDomainURL())\n",
    "        self.features.append(self.AnchorURL())\n",
    "        self.features.append(self.LinksInScriptTags())\n",
    "        self.features.append(self.ServerFormHandler())\n",
    "        self.features.append(self.InfoEmail())\n",
    "        self.features.append(self.WebsiteForwarding())\n",
    "    \n",
    "\n",
    "        self.features.append(self.DNSRecording())\n",
    "        self.features.append(self.WebsiteTraffic())\n",
    "        self.features.append(self.GoogleIndex())\n",
    "        self.features.append(self.LinksPointingToPage())\n",
    "        self.features.append(self.StatsReport())\n",
    "\n",
    "\n",
    "     # 1.UsingIp\n",
    "    def UsingIp(self):\n",
    "        try:\n",
    "            ipaddress.ip_address(self.url)\n",
    "            return -1\n",
    "        except:\n",
    "            return 1\n",
    "\n",
    "\n",
    "    # 2.shortUrl\n",
    "    def shortUrl(self):\n",
    "        match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n",
    "                    'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n",
    "                    'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n",
    "                    'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
    "                    'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
    "                    'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n",
    "                    'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|tr\\.im|link\\.zip\\.net', self.url)\n",
    "        if match:\n",
    "            return -1\n",
    "        return 1\n",
    "\n",
    "    \n",
    "    # 3.prefixSuffix\n",
    "    def prefixSuffix(self):\n",
    "        try:\n",
    "            match = re.findall('\\-', self.domain)\n",
    "            if match:\n",
    "                return -1\n",
    "            return 1\n",
    "        except:\n",
    "            return -1\n",
    "    \n",
    "    # 4.SubDomains\n",
    "    def SubDomains(self):\n",
    "        dot_count = len(re.findall(\"\\.\", self.url))\n",
    "        if dot_count == 1:\n",
    "            return 1\n",
    "        elif dot_count == 2:\n",
    "            return 0\n",
    "        return -1\n",
    "\n",
    "    # 5.HTTPS\n",
    "    def Hppts(self):\n",
    "        try:\n",
    "            https = self.urlparse.scheme\n",
    "            if 'https' in https:\n",
    "                return 1\n",
    "            return -1\n",
    "        except:\n",
    "            return 1\n",
    "\n",
    " \n",
    "\n",
    "    # 6. Favicon\n",
    "    def Favicon(self):\n",
    "        try:\n",
    "            for head in self.soup.find_all('head'):\n",
    "                for head.link in self.soup.find_all('link', href=True):\n",
    "                    dots = [x.start(0) for x in re.finditer('\\.', head.link['href'])]\n",
    "                    if self.url in head.link['href'] or len(dots) == 1 or domain in head.link['href']:\n",
    "                        return 1\n",
    "            return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 7. NonStdPort\n",
    "    def NonStdPort(self):\n",
    "        try:\n",
    "            port = self.domain.split(\":\")\n",
    "            if len(port)>1:\n",
    "                return -1\n",
    "            return 1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 8. HTTPSDomainURL\n",
    "    def HTTPSDomainURL(self):\n",
    "        try:\n",
    "            if 'https' in self.domain:\n",
    "                return -1\n",
    "            return 1\n",
    "        except:\n",
    "            return -1\n",
    "    \n",
    "   \n",
    "    # 9. AnchorURL\n",
    "    def AnchorURL(self):\n",
    "        try:\n",
    "            i,unsafe = 0,0\n",
    "            for a in self.soup.find_all('a', href=True):\n",
    "                if \"#\" in a['href'] or \"javascript\" in a['href'].lower() or \"mailto\" in a['href'].lower() or not (url in a['href'] or self.domain in a['href']):\n",
    "                    unsafe = unsafe + 1\n",
    "                i = i + 1\n",
    "\n",
    "            try:\n",
    "                percentage = unsafe / float(i) * 100\n",
    "                if percentage < 31.0:\n",
    "                    return 1\n",
    "                elif ((percentage >= 31.0) and (percentage < 67.0)):\n",
    "                    return 0\n",
    "                else:\n",
    "                    return -1\n",
    "            except:\n",
    "                return -1\n",
    "\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 1o. LinksInScriptTags\n",
    "    def LinksInScriptTags(self):\n",
    "        try:\n",
    "            i,success = 0,0\n",
    "        \n",
    "            for link in self.soup.find_all('link', href=True):\n",
    "                dots = [x.start(0) for x in re.finditer('\\.', link['href'])]\n",
    "                if self.url in link['href'] or self.domain in link['href'] or len(dots) == 1:\n",
    "                    success = success + 1\n",
    "                i = i+1\n",
    "\n",
    "            for script in self.soup.find_all('script', src=True):\n",
    "                dots = [x.start(0) for x in re.finditer('\\.', script['src'])]\n",
    "                if self.url in script['src'] or self.domain in script['src'] or len(dots) == 1:\n",
    "                    success = success + 1\n",
    "                i = i+1\n",
    "\n",
    "            try:\n",
    "                percentage = success / float(i) * 100\n",
    "                if percentage < 17.0:\n",
    "                    return 1\n",
    "                elif((percentage >= 17.0) and (percentage < 81.0)):\n",
    "                    return 0\n",
    "                else:\n",
    "                    return -1\n",
    "            except:\n",
    "                return 0\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 11. ServerFormHandler\n",
    "    def ServerFormHandler(self):\n",
    "        try:\n",
    "            if len(self.soup.find_all('form', action=True))==0:\n",
    "                return 1\n",
    "            else :\n",
    "                for form in self.soup.find_all('form', action=True):\n",
    "                    if form['action'] == \"\" or form['action'] == \"about:blank\":\n",
    "                        return -1\n",
    "                    elif self.url not in form['action'] and self.domain not in form['action']:\n",
    "                        return 0\n",
    "                    else:\n",
    "                        return 1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 12. InfoEmail\n",
    "    def InfoEmail(self):\n",
    "        try:\n",
    "            if re.findall(r\"[mail\\(\\)|mailto:?]\", self.soap):\n",
    "                return -1\n",
    "            else:\n",
    "                return 1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "  \n",
    "\n",
    "    # 13. WebsiteForwarding\n",
    "    def WebsiteForwarding(self):\n",
    "        try:\n",
    "            if len(self.response.history) <= 1:\n",
    "                return 1\n",
    "            elif len(self.response.history) <= 4:\n",
    "                return 0\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "             return -1\n",
    "\n",
    "\n",
    "    # 14. DNSRecording    \n",
    "    def DNSRecording(self):\n",
    "        try:\n",
    "            creation_date = self.whois_response.creation_date\n",
    "            try:\n",
    "                if(len(creation_date)):\n",
    "                    creation_date = creation_date[0]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            today  = date.today()\n",
    "            age = (today.year-creation_date.year)*12+(today.month-creation_date.month)\n",
    "            if age >=6:\n",
    "                return 1\n",
    "            return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 15. WebsiteTraffic   \n",
    "    def WebsiteTraffic(self):\n",
    "        try:\n",
    "            rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\"REACH\")['RANK']\n",
    "            if (int(rank) < 100000):\n",
    "                return 1\n",
    "            return 0\n",
    "        except :\n",
    "            return -1\n",
    "\n",
    " \n",
    "\n",
    "    # 16. GoogleIndex\n",
    "    def GoogleIndex(self):\n",
    "        try:\n",
    "            site = search(self.url, 5)\n",
    "            if site:\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return 1\n",
    "\n",
    "    # 17. LinksPointingToPage\n",
    "    def LinksPointingToPage(self):\n",
    "        try:\n",
    "            number_of_links = len(re.findall(r\"<a href=\", self.response.text))\n",
    "            if number_of_links == 0:\n",
    "                return 1\n",
    "            elif number_of_links <= 2:\n",
    "                return 0\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 18. StatsReport\n",
    "    def StatsReport(self):\n",
    "        try:\n",
    "            url_match = re.search(\n",
    "        'at\\.ua|usa\\.cc|baltazarpresentes\\.com\\.br|pe\\.hu|esy\\.es|hol\\.es|sweddy\\.com|myjino\\.ru|96\\.lt|ow\\.ly', url)\n",
    "            ip_address = socket.gethostbyname(self.domain)\n",
    "            ip_match = re.search('146\\.112\\.61\\.108|213\\.174\\.157\\.151|121\\.50\\.168\\.88|192\\.185\\.217\\.116|78\\.46\\.211\\.158|181\\.174\\.165\\.13|46\\.242\\.145\\.103|121\\.50\\.168\\.40|83\\.125\\.22\\.219|46\\.242\\.145\\.98|'\n",
    "                                '107\\.151\\.148\\.44|107\\.151\\.148\\.107|64\\.70\\.19\\.203|199\\.184\\.144\\.27|107\\.151\\.148\\.108|107\\.151\\.148\\.109|119\\.28\\.52\\.61|54\\.83\\.43\\.69|52\\.69\\.166\\.231|216\\.58\\.192\\.225|'\n",
    "                                '118\\.184\\.25\\.86|67\\.208\\.74\\.71|23\\.253\\.126\\.58|104\\.239\\.157\\.210|175\\.126\\.123\\.219|141\\.8\\.224\\.221|10\\.10\\.10\\.10|43\\.229\\.108\\.32|103\\.232\\.215\\.140|69\\.172\\.201\\.153|'\n",
    "                                '216\\.218\\.185\\.162|54\\.225\\.104\\.146|103\\.243\\.24\\.98|199\\.59\\.243\\.120|31\\.170\\.160\\.61|213\\.19\\.128\\.77|62\\.113\\.226\\.131|208\\.100\\.26\\.234|195\\.16\\.127\\.102|195\\.16\\.127\\.157|'\n",
    "                                '34\\.196\\.13\\.28|103\\.224\\.212\\.222|172\\.217\\.4\\.225|54\\.72\\.9\\.51|192\\.64\\.147\\.141|198\\.200\\.56\\.183|23\\.253\\.164\\.103|52\\.48\\.191\\.26|52\\.214\\.197\\.72|87\\.98\\.255\\.18|209\\.99\\.17\\.27|'\n",
    "                                '216\\.38\\.62\\.18|104\\.130\\.124\\.96|47\\.89\\.58\\.141|78\\.46\\.211\\.158|54\\.86\\.225\\.156|54\\.82\\.156\\.19|37\\.157\\.192\\.102|204\\.11\\.56\\.48|110\\.34\\.231\\.42', ip_address)\n",
    "            if url_match:\n",
    "                return -1\n",
    "            elif ip_match:\n",
    "                return -1\n",
    "            return 1\n",
    "        except:\n",
    "            return 1\n",
    "    \n",
    "    def getFeaturesList(self):\n",
    "        return self.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4f658c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed340d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
